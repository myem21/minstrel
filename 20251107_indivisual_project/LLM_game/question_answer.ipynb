{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92bba2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생각한 답(예: 동물, 인물, 물건 등)을 마음속에 떠올려 주세요.\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "404 Client Error: Not Found for url: https://api.runpod.ai/ollama/eeve",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m     40\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     25\u001b[39m     prompt = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m이전 응답: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhistory[-\u001b[32m1\u001b[39m][\u001b[33m'\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m다음 질문을 해줘.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m question, session_id = \u001b[43mollama_ask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msession_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAI의 질문 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mturn\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     28\u001b[39m answer = \u001b[38;5;28minput\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m당신의 대답 (예/아니오): \u001b[39m\u001b[33m\"\u001b[39m).strip()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mollama_ask\u001b[39m\u001b[34m(prompt, session_id)\u001b[39m\n\u001b[32m      8\u001b[39m payload = {\n\u001b[32m      9\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m: prompt,\n\u001b[32m     10\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msession_id\u001b[39m\u001b[33m\"\u001b[39m: session_id  \u001b[38;5;66;03m# 세션별로 대화 기록 관리\u001b[39;00m\n\u001b[32m     11\u001b[39m }\n\u001b[32m     12\u001b[39m response = requests.post(OLLAMA_API_URL, json=payload)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response.json()[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m], response.json().get(\u001b[33m\"\u001b[39m\u001b[33msession_id\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\AppData\\Local\\anaconda3\\envs\\llm_env\\Lib\\site-packages\\requests\\models.py:1026\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1021\u001b[39m     http_error_msg = (\n\u001b[32m   1022\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1023\u001b[39m     )\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 404 Client Error: Not Found for url: https://api.runpod.ai/ollama/eeve"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# Ollama EEVE API endpoint (예시용, 실제 엔드포인트로 수정해야 함)\n",
    "OLLAMA_API_URL = \"https://api.runpod.ai/ollama/eeve\"\n",
    "\n",
    "def ollama_ask(prompt, session_id=None):\n",
    "    payload = {\n",
    "        \"prompt\": prompt,\n",
    "        \"session_id\": session_id  # 세션별로 대화 기록 관리\n",
    "    }\n",
    "    response = requests.post(OLLAMA_API_URL, json=payload)\n",
    "    response.raise_for_status()\n",
    "    return response.json()[\"response\"], response.json().get(\"session_id\")\n",
    "\n",
    "def main():\n",
    "    print(\"생각한 답(예: 동물, 인물, 물건 등)을 마음속에 떠올려 주세요.\")\n",
    "    session_id = None\n",
    "    history = []\n",
    "    for turn in range(1, 21):\n",
    "        # Ollama에게 질문 요청, 이전 응답과 턴 수를 포함하여 프롬프트 구성\n",
    "        if turn == 1:\n",
    "            prompt = \"나는 스무고개 게임을 할거야. 네가 답을 머릿속에 생각했을 때, 내가 최대 20번의 예/아니오 질문으로 답을 맞출게. 첫번째 질문을 해줘.\"\n",
    "        else:\n",
    "            prompt = f\"이전 응답: {history[-1]['answer']}\\n다음 질문을 해줘.\"\n",
    "        question, session_id = ollama_ask(prompt, session_id)\n",
    "        print(f\"AI의 질문 {turn}: {question}\")\n",
    "        answer = input(\"당신의 대답 (예/아니오): \").strip()\n",
    "        history.append({'question': question, 'answer': answer})\n",
    "\n",
    "        # Ollama에게 모든 질문·답 내역 제공, 추측 요청\n",
    "        if turn >= 20 or answer.lower() in [\"정답\", \"맞음\"]:\n",
    "            guesses_prompt = (\n",
    "                \"지금까지의 질문과 대답:\\n\" +\n",
    "                \"\\n\".join([f\"Q: {x['question']} A: {x['answer']}\" for x in history]) +\n",
    "                \"\\n이 정보를 바탕으로 답을 추측해줘. 반드시 한 가지 정답만 말해.\"\n",
    "            )\n",
    "            guess, _ = ollama_ask(guesses_prompt, session_id)\n",
    "            print(f\"AI의 최종 답 추측: {guess}\")\n",
    "            break\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
